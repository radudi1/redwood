[Cache]

# If this is set to false caching will be completely disabled and you can ignore the rest of this file
Enabled = true

# If http response allows longer caching it will be capped to this many seconds.
MaxAge = 604800

# If response is larger than this many bytes it will not be cached
MaxSize = 33554432

# If don't have specific caching indications (eg: cache-control) we set expiration time to Age ("last-modified" header) / AgeDivisor
AgeDivisor = 10

# For some mimetypes (eg: video) we can set lower caching ttl.
# RestrictedMimePrefixes is an array of these mimetypes and RestrictedMaxAge is the maximum cache time in seconds
RestrictedMaxAge = 3600
RestrictedMimePrefixes = [ "video/" ]

# Compression levels for supported algorithms
# Choose wisely to balance computational cost on server with bandwidth and storage space savings
BrotliLevel = 1
GZIPLevel = 1
DeflateLevel = 1

# If set to true it will enable a mechanism which tries to detect servers (such as cloudlfare) that have problems with bumping (mitm interception)
# If such a problem is detected the domain will be added to noBump list
# Future connections to that domain will not be decrypted by Redwood and they will not be cached
AutoAddToNoBump = false


[Redis]

# Redis url to connect to - this is where cache will be saved
Url = "redis://redishost:6379"

# Redis DB number
DBNum = 0

# Maximum number of parallel connections to Redis
# New connections to redis are initiated and closed as needed up to this number
# The number should be a power of 2 - if not it will be floored to the closest power of 2
MaxNumConn = 4

# Redis can be pipelined
# This should decrease Redis load and improve performance especially for very busy servers
# but with the price of increased latency
# Greater values should increase performance and decrease Redis load but it may increase latency (from Redwood to Redis)
# and possibly produce load spikes on Redis
# MaxPipelineLen sets the maximum number of Redis commands that can be pipelined into a single Redis query
# The number should be a power of 2 - if not it will be floored to the closest power of 2
MaxPipelineLen = 256
# PipelineDeadlineUS sets the maximum amount of time in microseconds until the pipeline is waiting to receive more commands
# Set to 0 to disable waiting - decrease latency at the cost of decreased throughput and increased Redis load
PipelineDeadlineUS = 500


[Log]

# ResponseCache has it's own log
LogFile = "/var/log/redwood/responseCache.log"

# Revalidation mechanism (if enabled) has it's own log file
RevalidateLogFile = ""

# Logging messages are buffered. If you set a buffer that is too small processing threads will block waiting for the logging threads to finish
LogBufferSize = 4096


[Workers]

# Writing threads are priorised lower than client threads (http requests)
# This should slightly improve response time to client because cache writing is done in background only when no more clients are waiting for results
# But if you have a very busy server with no idle times (there's always at least one client waiting for response)
# then priorities don't make sends. In this scenario it will eventually behave like no priorities at all but with increased delay and overhead
# Therefore this setting disables priorities and all workers (http clients or cache writers) are given equal opportunity
PrioritiesEnabled = false

# When priorities are enabled lower priority tasks (eg: set, update ttl) will wait until all higher priority tasks finish (eg: get)
# For a busy server this could delay lower priority takss indefinitely
# This setting sets a limit for how many low priority tasks may wait
# When a this limit is reached a low priority task (random) will be allowed to execute regardless of whether higher priority tasks are still running
# Low priority tasks will still be delayed by they will eventually be executed even when high priority takss are running all the time
# Set lower values for lower delays and higher values if you know that there are idle times in client requests coming in and delays are acceptable
# Consider disabling priorities altogether if you have a very busy server
MaxBlockedWorkers = 1024


# All settings in StandardViolations violate http standards for improved cacheability
# !!! Do NOT use them unless you know what you're doing !!!
# !!! Things could break horribly !!!
# None of the settings will be applied if EnableStandardViolations is set to false
[StandardViolations]

# This is a kill-switch for all settings in StandardViolations section
# If disabled none of the other settings will be in effect (regardless of their value)
# If enabled it will already enable some minor standard violations which should be more or less safe
EnableStandardViolations = false

# If ServeStale is enabled stale responses will be served from cache and revalidation will kick in (in background)
# Make sure that you set RevalidateNumWorkers to something greater than 0
ServerStale = false

# According to standard s-maxage specifically sets intermediate cache ttls (redwood)
# But often times this is set too low compared to maxage
# If OverrideSMaxAge is set to true than cache ttl will be set to the maximum of s-maxage and maxage
OverrideSMaxAge = false

# If set to true then "Expires" header is ignored and cache ttl will be computed from last-modified / AgeDivisor
OverrideExpire = false

# Cache-control maxage headers can be ignored if OverrideCacheControl is set to true
# In this situation the algorithm works like this:
# We compute time since last-modified divided by AgeDivisor and we cap it to OverrideCacheControlMaxAge
# We get max-age from cache-control
# We set the ttl to be the maximum of the 2 values
# If no cache-control and no last-modified headers are present we try to set ttl to Age / AgeDivisor
# If set to true it's behavior implies OverrideExpire set to true as well
OverrideCacheControl = false
OverrideCacheControlMaxAge = 43200

# Is DefaultAge is greater than 0 and there are no headers on which we can compute caching ttl
# the response will be cached for DefaultAge seconds
DefaultAge = 0

# WARNING!!! THIS SETTING ENABLES REALLY DANGEROUS HEURISTICS THAT CAN BREAK THINGS BADLY
# THIS WILL ALSO LEAD TO SERIOUS SECURITY AND PRIVACY PROBLEMS
# DO NOT ENABLE THIS!!!
EnableDangerousHeuristics = false